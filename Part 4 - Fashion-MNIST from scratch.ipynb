{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages\n",
    "* matplotlib.pyplot for plotting\n",
    "* [`OrderedDict`](https://docs.python.org/2/library/collections.html#ordereddict-objects) from collections: \"Ordered dictionaries are just like regular dictionaries but they remember the order that items were inserted. When iterating over an ordered dictionary, the items are returned in the order their keys were first added.\"\n",
    "* [`torch.nn`](https://pytorch.org/docs/stable/nn.html) for building the neuronal network\n",
    "* [`torch.nn.optim`](https://pytorch.org/docs/stable/optim.html) to use the optimizer algorithms like SGD or Adam to update the weights.\n",
    "* [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html#) for the neuronal network functions like activation functions, dropout functions etc.\n",
    "* [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html) to get different datasets like MNIST, FASHION MINIST, CIFAR etc. \n",
    "* [`torchvision.models`](https://pytorch.org/docs/stable/torchvision/models.html) to get different neuronal network models like AlexNet, VGG, DensNet, etc.\n",
    "* [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) for image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the device. The device is either cuda:0 for GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Get the `MNIST` dataset divided into the trainset and the testset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, ),(0.5,))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "# print(image[0].shape)\n",
    "a = image[0].numpy()\n",
    "# print(a)\n",
    "# print(a[0].shape)\n",
    "plt.imshow(a[0])\n",
    "helper.imshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "There are two possible ways to build a network: 1. a static one 2. a dynamic one. \n",
    "<br>\n",
    "\n",
    "The dynamic one allows us to configure as many hidden layers as we want just by modifying a patrameter list of the hidden layers. This is done with the help of [`nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#modulelist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: static definition** of the neuronal network by using \n",
    "```python\n",
    "nn.Sequential(OrderedDict([]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fcl1): Linear(in_features=784, out_features=800, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fcl2): Linear(in_features=800, out_features=400, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fcl3): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fcl4): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fcl5): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (out): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the hyperparameter\n",
    "inpot_layer_size = 784\n",
    "hidden_layer_size = [800, 400, 200, 100, 50]\n",
    "output_layer_size= 10\n",
    "\n",
    "netmodel = nn.Sequential(OrderedDict([\n",
    "    ('fcl1', nn.Linear(inpot_layer_size, hidden_layer_size[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fcl2', nn.Linear(hidden_layer_size[0], hidden_layer_size[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fcl3', nn.Linear(hidden_layer_size[1], hidden_layer_size[2])),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('fcl4', nn.Linear(hidden_layer_size[2], hidden_layer_size[3])),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('fcl5', nn.Linear(hidden_layer_size[3], hidden_layer_size[4])),\n",
    "    ('relu5', nn.ReLU()),\n",
    "    ('out', nn.Linear(hidden_layer_size[4], output_layer_size))\n",
    "]))\n",
    "\n",
    "netmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: dynamic definition of the neuronal network by using [`nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#modulelist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size, dropout_p = 0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers!\n",
    "        \n",
    "            Arguments:\n",
    "            ----------\n",
    "            input_size: integer, size of the input\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            output_size: integer, size of the output layer\n",
    "            dropout_p: float between 0 and 1, dropout probability\n",
    "        '''\n",
    "        # call the __init()__ function of nn.Module\n",
    "        super().__init__()\n",
    "        # Add the first layer -> input to a hidden layer. This is equivalent to 'fcl1' of the static network\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable numbers of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # Add the output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Define dropout\n",
    "        self.dropout = nn.Dropout(p = dropout_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network.\n",
    "        \n",
    "            Arguments:\n",
    "            ---------\n",
    "            x: torch tensor, input to the network\n",
    "            \n",
    "            Return:\n",
    "            -------\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        # return the log_softmax. the log-softmax is a log probability \n",
    "        # which comes with a lot of benefits. Using the log probability, \n",
    "        # computations are often faster and more accurate.\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        images.resize_(images.shape[0], 784)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        \n",
    "        test_loss += criterion(output, labels).item()\n",
    "        \n",
    "#         loss = criterion(output, labels)\n",
    "#         lest_loss += loss.item()\n",
    "\n",
    "        # take the exponentiol because the output is in log probability (log_softmax)\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Make a single cycle consisting of:\n",
    "1. **Definition of the loss function**. This is needed to calculate the loss / difference between the result of the forward pass through the network and the true value (=label) -> `criterion = nn.CrossEntropyLoss()`\n",
    "2. **Definition of the optimizer function**. The optimizer function updates the defined parameters (=weights of the network) -> `optimizer = optim.Adam(netmodel.parameters(), lr=0.01)`\n",
    "* **Move the model to device** ( this is either the CPU or the GPU) -> `netmodel.to(device)`\n",
    "* **Get the images and the corresponding labels** -> `images, labels = next(iter(trainloader))`\n",
    "* **Flatten the images** into an element vector -> `images.resize_(images.size()[0], 784)`\n",
    "* **Move the torch tensors *images* and *labels* to device** (this is either the CPU or the GPU) -> `images, labels = images.to(device), labels.to(device)`\n",
    "* **Clear the gradients**. This is necessary because the gradients are accumulated during the backward pass. -> `optimizer.zero_grad()`\n",
    "* **Forward pass** through the network -> `output = netmodel.forward(images)`\n",
    "* **Calculate the loss** -> `loss = criterion(output, labels)`\n",
    "* **Backwards pass** to calculate the gradients  -> `loss.backward()`\n",
    "* **Update the weights** -> `optimizer.step()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the network - dynamic or static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnDynamic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=800, bias=True)\n",
       "    (1): Linear(in_features=800, out_features=800, bias=True)\n",
       "    (2): Linear(in_features=800, out_features=600, bias=True)\n",
       "    (3): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (4): Linear(in_features=600, out_features=400, bias=True)\n",
       "    (5): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (6): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (7): Linear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=200, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if nnDynamic == False:\n",
    "    # define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # define the optimizer and pass in the network parameters that should be optimized and the learning rate \n",
    "    optimizer = optim.Adam(netmodel.parameters(), lr=0.01)\n",
    "else:\n",
    "    input_layer_size = 784\n",
    "    output_layer_size = 10\n",
    "#     hidden_layers_list = [512, 256, 128, 64]\n",
    "    hidden_layers_list = [800, 800, 600, 600, 400, 400, 200, 200]\n",
    "    dropout_p = 0.0\n",
    "    # create the netmodel\n",
    "    netmodel = Network(input_layer_size,hidden_layers_list, output_layer_size, dropout_p)\n",
    "    # define the loss function\n",
    "    criterion = nn.NLLLoss()\n",
    "    # define the optimizer and pass in the network parameters that should be optimized and the learning rate \n",
    "    optimizer = optim.Adam(netmodel.parameters(), lr=0.003)\n",
    "netmodel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# # define the loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # define the optimizer and pass in the network parameters that should be optimized and the learning rate \n",
    "# optimizer = optim.Adam(netmodel.parameters(), lr=0.01)\n",
    "\n",
    "# move the model to device (this is either the CPU or the GPU)\n",
    "netmodel.to(device)\n",
    "\n",
    "# get the next batch of images and labels\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "\n",
    "# flatten the image into a 784 (28x28) element vector\n",
    "images.resize_(images.size()[0], 784)\n",
    "print(images.shape)\n",
    "\n",
    "# move the torch tensors images and labels to device (this is either the CPU or the GPU)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# forwardpass through the network\n",
    "output = netmodel.forward(images)\n",
    "\n",
    "# calculate the loss / error between the output and the true labels\n",
    "loss = criterion(output, labels)\n",
    "print('Loss: ', loss)\n",
    "\n",
    "# calculate the gradients\n",
    "loss.backward()\n",
    "\n",
    "# update the weights\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4...  Training loss: 2.078 Test Loss: 1.467..  Test Accuracy: 0.298\n",
      "Epoch: 1/4...  Training loss: 1.336 Test Loss: 1.477..  Test Accuracy: 0.406\n",
      "Epoch: 1/4...  Training loss: 1.167 Test Loss: 1.063..  Test Accuracy: 0.549\n",
      "Epoch: 1/4...  Training loss: 1.010 Test Loss: 0.939..  Test Accuracy: 0.575\n",
      "Epoch: 1/4...  Training loss: 0.981 Test Loss: 0.969..  Test Accuracy: 0.612\n",
      "Epoch: 1/4...  Training loss: 0.907 Test Loss: 0.835..  Test Accuracy: 0.670\n",
      "Epoch: 1/4...  Training loss: 0.810 Test Loss: 0.775..  Test Accuracy: 0.679\n",
      "Epoch: 1/4...  Training loss: 0.791 Test Loss: 0.772..  Test Accuracy: 0.661\n",
      "Epoch: 1/4...  Training loss: 0.785 Test Loss: 0.761..  Test Accuracy: 0.696\n",
      "Epoch: 1/4...  Training loss: 0.823 Test Loss: 0.711..  Test Accuracy: 0.712\n",
      "Epoch: 1/4...  Training loss: 0.733 Test Loss: 0.733..  Test Accuracy: 0.696\n",
      "Epoch: 1/4...  Training loss: 0.735 Test Loss: 0.767..  Test Accuracy: 0.699\n",
      "Epoch: 1/4...  Training loss: 0.705 Test Loss: 0.688..  Test Accuracy: 0.723\n",
      "Epoch: 1/4...  Training loss: 0.704 Test Loss: 0.679..  Test Accuracy: 0.726\n",
      "Epoch: 1/4...  Training loss: 0.684 Test Loss: 0.742..  Test Accuracy: 0.730\n",
      "Epoch: 1/4...  Training loss: 0.659 Test Loss: 0.670..  Test Accuracy: 0.755\n",
      "Epoch: 1/4...  Training loss: 0.605 Test Loss: 0.713..  Test Accuracy: 0.726\n",
      "Epoch: 1/4...  Training loss: 0.664 Test Loss: 0.618..  Test Accuracy: 0.746\n",
      "Epoch: 1/4...  Training loss: 0.605 Test Loss: 0.626..  Test Accuracy: 0.756\n",
      "Epoch: 1/4...  Training loss: 0.598 Test Loss: 0.619..  Test Accuracy: 0.741\n",
      "Epoch: 1/4...  Training loss: 0.655 Test Loss: 0.602..  Test Accuracy: 0.766\n",
      "Epoch: 1/4...  Training loss: 0.644 Test Loss: 0.750..  Test Accuracy: 0.723\n",
      "Epoch: 1/4...  Training loss: 0.638 Test Loss: 0.618..  Test Accuracy: 0.774\n",
      "Epoch: 2/4...  Training loss: 0.329 Test Loss: 0.596..  Test Accuracy: 0.774\n",
      "Epoch: 2/4...  Training loss: 0.549 Test Loss: 0.600..  Test Accuracy: 0.774\n",
      "Epoch: 2/4...  Training loss: 0.598 Test Loss: 0.610..  Test Accuracy: 0.781\n",
      "Epoch: 2/4...  Training loss: 0.596 Test Loss: 0.579..  Test Accuracy: 0.774\n",
      "Epoch: 2/4...  Training loss: 0.563 Test Loss: 0.621..  Test Accuracy: 0.788\n",
      "Epoch: 2/4...  Training loss: 0.559 Test Loss: 0.556..  Test Accuracy: 0.800\n",
      "Epoch: 2/4...  Training loss: 0.543 Test Loss: 0.539..  Test Accuracy: 0.809\n",
      "Epoch: 2/4...  Training loss: 0.551 Test Loss: 0.591..  Test Accuracy: 0.793\n",
      "Epoch: 2/4...  Training loss: 0.522 Test Loss: 0.535..  Test Accuracy: 0.806\n",
      "Epoch: 2/4...  Training loss: 0.527 Test Loss: 0.582..  Test Accuracy: 0.791\n",
      "Epoch: 2/4...  Training loss: 0.558 Test Loss: 0.576..  Test Accuracy: 0.801\n",
      "Epoch: 2/4...  Training loss: 0.540 Test Loss: 0.546..  Test Accuracy: 0.812\n",
      "Epoch: 2/4...  Training loss: 0.564 Test Loss: 0.542..  Test Accuracy: 0.798\n",
      "Epoch: 2/4...  Training loss: 0.590 Test Loss: 0.562..  Test Accuracy: 0.812\n",
      "Epoch: 2/4...  Training loss: 0.529 Test Loss: 0.549..  Test Accuracy: 0.811\n",
      "Epoch: 2/4...  Training loss: 0.520 Test Loss: 0.535..  Test Accuracy: 0.811\n",
      "Epoch: 2/4...  Training loss: 0.527 Test Loss: 0.517..  Test Accuracy: 0.812\n",
      "Epoch: 2/4...  Training loss: 0.490 Test Loss: 0.508..  Test Accuracy: 0.826\n",
      "Epoch: 2/4...  Training loss: 0.507 Test Loss: 0.561..  Test Accuracy: 0.811\n",
      "Epoch: 2/4...  Training loss: 0.513 Test Loss: 0.512..  Test Accuracy: 0.825\n",
      "Epoch: 2/4...  Training loss: 0.535 Test Loss: 0.614..  Test Accuracy: 0.814\n",
      "Epoch: 2/4...  Training loss: 0.476 Test Loss: 0.546..  Test Accuracy: 0.819\n",
      "Epoch: 2/4...  Training loss: 0.507 Test Loss: 0.565..  Test Accuracy: 0.791\n",
      "Epoch: 3/4...  Training loss: 0.056 Test Loss: 0.507..  Test Accuracy: 0.827\n",
      "Epoch: 3/4...  Training loss: 0.486 Test Loss: 0.520..  Test Accuracy: 0.821\n",
      "Epoch: 3/4...  Training loss: 0.450 Test Loss: 0.494..  Test Accuracy: 0.829\n",
      "Epoch: 3/4...  Training loss: 0.533 Test Loss: 0.545..  Test Accuracy: 0.808\n",
      "Epoch: 3/4...  Training loss: 0.490 Test Loss: 0.486..  Test Accuracy: 0.831\n",
      "Epoch: 3/4...  Training loss: 0.538 Test Loss: 0.622..  Test Accuracy: 0.758\n",
      "Epoch: 3/4...  Training loss: 0.510 Test Loss: 0.509..  Test Accuracy: 0.823\n",
      "Epoch: 3/4...  Training loss: 0.461 Test Loss: 0.500..  Test Accuracy: 0.826\n",
      "Epoch: 3/4...  Training loss: 0.462 Test Loss: 0.564..  Test Accuracy: 0.807\n",
      "Epoch: 3/4...  Training loss: 0.486 Test Loss: 0.503..  Test Accuracy: 0.827\n",
      "Epoch: 3/4...  Training loss: 0.473 Test Loss: 0.532..  Test Accuracy: 0.815\n",
      "Epoch: 3/4...  Training loss: 0.440 Test Loss: 0.518..  Test Accuracy: 0.833\n",
      "Epoch: 3/4...  Training loss: 0.471 Test Loss: 0.485..  Test Accuracy: 0.833\n",
      "Epoch: 3/4...  Training loss: 0.506 Test Loss: 0.514..  Test Accuracy: 0.843\n",
      "Epoch: 3/4...  Training loss: 0.466 Test Loss: 0.496..  Test Accuracy: 0.833\n",
      "Epoch: 3/4...  Training loss: 0.488 Test Loss: 0.488..  Test Accuracy: 0.841\n",
      "Epoch: 3/4...  Training loss: 0.460 Test Loss: 0.497..  Test Accuracy: 0.835\n",
      "Epoch: 3/4...  Training loss: 0.464 Test Loss: 0.503..  Test Accuracy: 0.838\n",
      "Epoch: 3/4...  Training loss: 0.483 Test Loss: 0.570..  Test Accuracy: 0.834\n",
      "Epoch: 3/4...  Training loss: 0.578 Test Loss: 0.528..  Test Accuracy: 0.820\n",
      "Epoch: 3/4...  Training loss: 0.481 Test Loss: 0.496..  Test Accuracy: 0.836\n",
      "Epoch: 3/4...  Training loss: 0.485 Test Loss: 0.527..  Test Accuracy: 0.832\n",
      "Epoch: 3/4...  Training loss: 0.433 Test Loss: 0.464..  Test Accuracy: 0.844\n",
      "Epoch: 3/4...  Training loss: 0.412 Test Loss: 0.477..  Test Accuracy: 0.836\n",
      "Epoch: 4/4...  Training loss: 0.262 Test Loss: 0.500..  Test Accuracy: 0.828\n",
      "Epoch: 4/4...  Training loss: 0.411 Test Loss: 0.488..  Test Accuracy: 0.846\n",
      "Epoch: 4/4...  Training loss: 0.446 Test Loss: 0.513..  Test Accuracy: 0.829\n",
      "Epoch: 4/4...  Training loss: 0.441 Test Loss: 0.475..  Test Accuracy: 0.840\n",
      "Epoch: 4/4...  Training loss: 0.451 Test Loss: 0.458..  Test Accuracy: 0.838\n",
      "Epoch: 4/4...  Training loss: 0.402 Test Loss: 0.472..  Test Accuracy: 0.832\n",
      "Epoch: 4/4...  Training loss: 0.410 Test Loss: 0.493..  Test Accuracy: 0.832\n",
      "Epoch: 4/4...  Training loss: 0.444 Test Loss: 0.481..  Test Accuracy: 0.840\n",
      "Epoch: 4/4...  Training loss: 0.402 Test Loss: 0.502..  Test Accuracy: 0.829\n",
      "Epoch: 4/4...  Training loss: 0.444 Test Loss: 0.450..  Test Accuracy: 0.849\n",
      "Epoch: 4/4...  Training loss: 0.432 Test Loss: 0.454..  Test Accuracy: 0.845\n",
      "Epoch: 4/4...  Training loss: 0.446 Test Loss: 0.440..  Test Accuracy: 0.846\n",
      "Epoch: 4/4...  Training loss: 0.449 Test Loss: 0.437..  Test Accuracy: 0.846\n",
      "Epoch: 4/4...  Training loss: 0.393 Test Loss: 0.445..  Test Accuracy: 0.851\n",
      "Epoch: 4/4...  Training loss: 0.407 Test Loss: 0.462..  Test Accuracy: 0.839\n",
      "Epoch: 4/4...  Training loss: 0.423 Test Loss: 0.443..  Test Accuracy: 0.843\n",
      "Epoch: 4/4...  Training loss: 0.422 Test Loss: 0.458..  Test Accuracy: 0.847\n",
      "Epoch: 4/4...  Training loss: 0.408 Test Loss: 0.462..  Test Accuracy: 0.842\n",
      "Epoch: 4/4...  Training loss: 0.392 Test Loss: 0.442..  Test Accuracy: 0.852\n",
      "Epoch: 4/4...  Training loss: 0.377 Test Loss: 0.467..  Test Accuracy: 0.842\n",
      "Epoch: 4/4...  Training loss: 0.391 Test Loss: 0.461..  Test Accuracy: 0.851\n",
      "Epoch: 4/4...  Training loss: 0.417 Test Loss: 0.450..  Test Accuracy: 0.846\n",
      "Epoch: 4/4...  Training loss: 0.443 Test Loss: 0.431..  Test Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "# # define the loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # define the optimizer and pass in the network parameters that should be optimized and the learning rate \n",
    "# optimizer = optim.Adam(netmodel.parameters(), lr=0.01)\n",
    "\n",
    "# set the number of epochs. One epoch is a pass through the entire dataset (= training set)\n",
    "epochs = 4\n",
    "# print everey 40 steps the averaged loss over these 40 steps\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "# move the model to device ( this con be either the CPU or the GPU)\n",
    "netmodel.to(device)\n",
    "\n",
    "for e in range(epochs):\n",
    "    # accumulate the loss\n",
    "    running_loss = 0\n",
    "    # iterate over the training set\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        # flatten the image into a 784 (28x28) element vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # move the torch tensors images and labels to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Clear the gradients, because backward accumulates the gradients and so they have to be cleared\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass through the network\n",
    "        output = netmodel.forward(images)\n",
    "\n",
    "        # calculate the loss / error between the output and the true labels\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumulate the loss / cost\n",
    "        # loss is a scalar tensor therefore .item() is needed to get the value out of the tensor\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            if nnDynamic == True:\n",
    "                # Make sure network is in eval mode for inference\n",
    "                netmodel.eval()\n",
    "\n",
    "                # Turn off gradients for validation, saves memory and computations\n",
    "                with torch.no_grad():\n",
    "                    # call validation to validate the model\n",
    "                    test_loss, accuracy = validation(netmodel, testloader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                      \"Training loss: {:.3f}\".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "#                 running_loss = 0\n",
    "                \n",
    "                # Make sure training is back on\n",
    "                netmodel.train()\n",
    "            else:\n",
    "                print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                      \"Training loss: {:.3f}\".format(running_loss/print_every))\n",
    "\n",
    "            running_loss = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/horst/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "netmodel.to('cpu')\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "ps = F.softmax(netmodel.forward(img))\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
