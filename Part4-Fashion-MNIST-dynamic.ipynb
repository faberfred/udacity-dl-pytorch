{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages\n",
    "* matplotlib.pyplot for plotting\n",
    "* [`OrderedDict`](https://docs.python.org/2/library/collections.html#ordereddict-objects) from collections: \"Ordered dictionaries are just like regular dictionaries but they remember the order that items were inserted. When iterating over an ordered dictionary, the items are returned in the order their keys were first added.\"\n",
    "* [`torch.nn`](https://pytorch.org/docs/stable/nn.html) for building the neuronal network\n",
    "* [`torch.nn.optim`](https://pytorch.org/docs/stable/optim.html) to use the optimizer algorithms like SGD or Adam to update the weights.\n",
    "* [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html#) for the neuronal network functions like activation functions, dropout functions etc.\n",
    "* [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html) to get different datasets like MNIST, FASHION MINIST, CIFAR etc. \n",
    "* [`torchvision.models`](https://pytorch.org/docs/stable/torchvision/models.html) to get different (pretrained) neuronal network models like AlexNet, VGG, DensNet, etc.\n",
    "* [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) for image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the device. The device is either cuda:0 for GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Get the `MNIST` dataset divided into the trainset and the testset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, ),(0.5,))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "# print(image[0].shape)\n",
    "a = image[0].numpy()\n",
    "# print(a)\n",
    "# print(a[0].shape)\n",
    "plt.imshow(a[0])\n",
    "helper.imshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "There are two possible ways to build a network: 1. a static one 2. a dynamic one. \n",
    "<br>\n",
    "**Within this notebook we will use the dynamic one**\n",
    "<br>\n",
    "The dynamic one allows us to configure as many hidden layers as we want just by modifying a patrameter list of the hidden layers. This is done with the help of [`nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#modulelist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: dynamic definition of the neuronal network by using [`nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#modulelist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size, dropout_p = 0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers!\n",
    "        \n",
    "            Arguments:\n",
    "            ----------\n",
    "            input_size: integer, size of the input\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            output_size: integer, size of the output layer\n",
    "            dropout_p: float between 0 and 1, dropout probability\n",
    "        '''\n",
    "        # call the __init()__ function of nn.Module\n",
    "        super().__init__()\n",
    "        # Add the first layer -> input to a hidden layer. This is equivalent to 'fcl1' of the static network\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable numbers of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # Add the output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Define dropout\n",
    "        self.dropout = nn.Dropout(p = dropout_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network.\n",
    "        \n",
    "            Arguments:\n",
    "            ---------\n",
    "            x: torch tensor, input to the network\n",
    "            \n",
    "            Return:\n",
    "            -------\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        # return the log_softmax. the log-softmax is a log probability \n",
    "        # which comes with a lot of benefits. Using the log probability, \n",
    "        # computations are often faster and more accurate.\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # move the model to device ( this con be either the CPU or the GPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    for images, labels in testloader:\n",
    "        # flatten the image into a 784 (28x28) element vector\n",
    "        images.resize_(images.shape[0], 784)\n",
    "        \n",
    "         # move the torch tensors images and labels to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # forward pass through the network\n",
    "        output = model.forward(images)\n",
    "        \n",
    "        # calculate the loss / error between the output and the true labels and accumulate the loss / cost\n",
    "        # loss is a scalar tensor therefore .item() is needed to get the value out of the tensor\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        \n",
    "#         loss = criterion(output, labels)\n",
    "#         lest_loss += loss.item()\n",
    "\n",
    "        # take the exponentiol because the output is in log probability (log_softmax)\n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        \n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Make a single cycle consisting of:\n",
    "1. **Definition of the loss function**. This is needed to calculate the loss / difference between the result of the forward pass through the network and the true value (=label) -> `criterion = nn.CrossEntropyLoss()`\n",
    "2. **Definition of the optimizer function**. The optimizer function updates the defined parameters (=weights of the network) -> `optimizer = optim.Adam(netmodel.parameters(), lr=0.01)`\n",
    "* **Move the model to device** ( this is either the CPU or the GPU) -> `netmodel.to(device)`\n",
    "* **Get the images and the corresponding labels** -> `images, labels = next(iter(trainloader))`\n",
    "* **Flatten the images** into an element vector -> `images.resize_(images.size()[0], 784)`\n",
    "* **Move the torch tensors *images* and *labels* to device** (this is either the CPU or the GPU) -> `images, labels = images.to(device), labels.to(device)`\n",
    "* **Clear the gradients**. This is necessary because the gradients are accumulated during the backward pass. -> `optimizer.zero_grad()`\n",
    "* **Forward pass** through the network -> `output = netmodel.forward(images)`\n",
    "* **Calculate the loss** -> `loss = criterion(output, labels)`\n",
    "* **Backwards pass** to calculate the gradients  -> `loss.backward()`\n",
    "* **Update the weights** -> `optimizer.step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 784\n",
    "output_layer_size = 10\n",
    "hidden_layers_list = [512, 256, 128, 64]\n",
    "# hidden_layers_list = [800, 700, 600, 500, 400, 300, 200, 100, 50, 25]\n",
    "# hidden_layers_list = [800, 800, 600, 600, 400, 400, 200, 200]\n",
    "dropout_p = 0.1\n",
    "# create the netmodel\n",
    "netmodel = Network(input_layer_size,hidden_layers_list, output_layer_size, dropout_p)\n",
    "\n",
    "netmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "criterion = nn.NLLLoss()\n",
    "# define the optimizer and pass in the network parameters that should be optimized and the learning rate \n",
    "optimizer = optim.Adam(netmodel.parameters(), lr=0.003)\n",
    "\n",
    "# set the number of epochs. One epoch is a pass through the entire dataset (= training set)\n",
    "epochs = 4\n",
    "# print everey 40 steps the averaged loss over these 40 steps\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "# move the model to device ( this con be either the CPU or the GPU)\n",
    "netmodel.to(device)\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Make sure training is on\n",
    "    # -> Turn ON dropout functionality in training mode\n",
    "    netmodel.train()\n",
    "    # accumulate the loss\n",
    "    running_loss = 0\n",
    "    # iterate over the training set\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        # flatten the image into a 784 (28x28) element vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # move the torch tensors images and labels to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Clear the gradients, because backward accumulates the gradients and so they have to be cleared\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass through the network\n",
    "        output = netmodel.forward(images)\n",
    "\n",
    "        # calculate the loss / error between the output and the true labels\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumulate the loss / cost\n",
    "        # loss is a scalar tensor therefore .item() is needed to get the value out of the tensor\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            # Make sure network is in eval mode for inference\n",
    "            # -> Turn OFF the dropout functionality in evaluation mode\n",
    "            netmodel.eval()\n",
    "\n",
    "            # Turn off gradient computation for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                # call validation to validate the model\n",
    "                test_loss, accuracy = validation(netmodel, testloader, criterion)\n",
    "\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Training loss: {:.3f}\".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "#                 running_loss = 0\n",
    "\n",
    "            # Make sure training is back on\n",
    "            # -> Turn ON dropout functionality in training mode\n",
    "            netmodel.train()\n",
    "\n",
    "            running_loss = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out your network!\n",
    "netmodel.to('cpu')\n",
    "\n",
    "netmodel.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = netmodel.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
